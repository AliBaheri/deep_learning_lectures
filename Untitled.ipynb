{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "In this tutorial we will see how to define, train and visualize a Convolutional Neural Network (CNN) for image classification using the [Keras](https://keras.io/) library.\n",
    "\n",
    "## From theory...\n",
    "\n",
    "Recall (see [here](http://cs231n.github.io/convolutional-networks/) for details):\n",
    "\n",
    "> Convolutional Neural Networks are very similar to ordinary Neural Networks from the previous chapter: they are made up of neurons that have learnable weights and biases. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. So what does change? ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network.\n",
    "\n",
    "Most CNNs have a feed-forward architecture and are tipically composed of [Convolutional](https://keras.io/layers/convolutional/), [Pooling](https://keras.io/layers/pooling/) and [Fully-Connected](https://keras.io/layers/core/#dense) layers.\n",
    "\n",
    "CNN models first demonstrated their effectiveness for task of classification. In this context, a [Softmax](https://keras.io/activations/) activation after the last Dense layer encodes the probability distribution over the classes and the loss function employed is the categorical [cross-entropy](https://keras.io/objectives/).\n",
    "\n",
    "More recently CNNs have been successfully employed to tackle a huge variety of problems, including e.g. semantic segmentation, visual attention, edge detection, image and video captioning etc. (see e.g. [here](https://github.com/kjw0612/awesome-deep-vision) for some examples). In order to deal with these different tasks, network architectures have evolved too from simple feed-forward to arbitrarily complex models.\n",
    "\n",
    "## ...to practice.\n",
    "\n",
    "[Keras](https://keras.io/) library provides facility for both the [feed-forward](https://keras.io/models/sequential/) and for [more complex](https://keras.io/getting-started/functional-api-guide/) architectures. The latter can be used for defining composite models, such as multi-output models, directed acyclic graphs, or models with shared layers.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {
    "523a7dae-c51d-4dcf-8e26-1a88d05fa795": {
     "id": "523a7dae-c51d-4dcf-8e26-1a88d05fa795",
     "prev": "c7d07a25-8a15-4d9c-b1d4-a57fe844e2e5",
     "regions": {
      "b5818082-2dce-4a8b-a801-ccd7cb39b83b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "3528348c-c1b8-4c09-9cb6-4dd5772c2a87",
        "part": "whole"
       },
       "id": "b5818082-2dce-4a8b-a801-ccd7cb39b83b"
      }
     }
    },
    "a0a6c0ee-bb21-4d9f-8886-42a5ebe48df0": {
     "id": "a0a6c0ee-bb21-4d9f-8886-42a5ebe48df0",
     "prev": "523a7dae-c51d-4dcf-8e26-1a88d05fa795",
     "regions": {
      "62d069a1-5662-4680-aa7f-60a2dd6b1a98": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f8c3e7fd-5711-429c-9398-a24c43950197",
        "part": "whole"
       },
       "id": "62d069a1-5662-4680-aa7f-60a2dd6b1a98"
      }
     }
    },
    "c7d07a25-8a15-4d9c-b1d4-a57fe844e2e5": {
     "id": "c7d07a25-8a15-4d9c-b1d4-a57fe844e2e5",
     "prev": "f09912f6-3947-462a-ac87-43abff450e5c",
     "regions": {
      "dd7feb31-2640-4e6c-9bfa-6066fbe4bf87": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "983e7694-97d7-4c99-abed-8cdfb0e78020",
        "part": "whole"
       },
       "id": "dd7feb31-2640-4e6c-9bfa-6066fbe4bf87"
      }
     }
    },
    "f09912f6-3947-462a-ac87-43abff450e5c": {
     "id": "f09912f6-3947-462a-ac87-43abff450e5c",
     "prev": null,
     "regions": {
      "262ac9d3-e3d3-47bc-8b19-ac08ab2e553e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4e5bbdc5-00cd-4457-a619-fa315f702739",
        "part": "whole"
       },
       "id": "262ac9d3-e3d3-47bc-8b19-ac08ab2e553e"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
