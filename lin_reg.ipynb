{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with Theano\n",
    "In this tutorial we will move the first steps in the [Theano](http://deeplearning.net/software/theano/) library, a popular tensor manipulation library that provides automatic differentiation. We will learn the basics implementing a simple linear regression solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember multivariate linear regression?\n",
    "\n",
    "Recall that given a dataset $\\{(x_i, y_i)\\}_{i=0}^N$, with $x_i \\in \\mathbb{R}^d, y_i \\in \\mathbb{R}$, the objective of linear regression is to find a vector $w \\in \\mathbb{R}^d$ and a scalar $b$ such that $y = w^Tx + b$ fits the dataset. In this tutorial we will learn $w$ and $b$ using SGD and a Mean Square Error (MSE) loss:\n",
    "\n",
    "$$L = \\frac{1}{N} \\sum_{i=0}^N (w^Tx_i + b - y_i)^2$$\n",
    "\n",
    "Starting from random values, parameters $w$ and $b$ will be updated at each iteration via the following rule:\n",
    "\n",
    "$$w_t = w_{t-1} - \\eta \\frac{\\partial L}{\\partial w}$$\n",
    "$$b_t = b_{t-1} - \\eta \\frac{\\partial L}{\\partial b}$$\n",
    "\n",
    "where $\\eta$ represents the learning rate of our optimizer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A real problem to solve\n",
    "Data we will use is from the [House Pricing Kaggle Competition](http://www.kaggle.com/c/house-prices-advanced-regression-techniques/). The proposed challenge is to predict a house price given other 79 variables, describing various aspects of it. Notice that this problem is hard and highly non-linear but, for the sake of this tutorial, we will use only real-valued features (about 30 variables) and a linear model.\n",
    "The function we will use to load data will\n",
    "* load data from the csv file into a numpy array;\n",
    "* remove columns containing non numerical or incomplete data;\n",
    "* shuffle the entire set\n",
    "* separate observations from targets\n",
    "* optionally add artificial quadratic features (simply as product of the existing ones)\n",
    "* split into training and validation samples\n",
    "\n",
    "and will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Quadro K2200 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168L, 33L)\n",
      "1168 Training samples\n",
      "292 Validation samples\n",
      "33 observed variables\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def get_data(non_linearities=False, train_ratio=0.8):\n",
    "\n",
    "    # Load data\n",
    "    data = np.genfromtxt('train.csv', delimiter=',').astype(np.float32)\n",
    "    data = data[:, ~np.isnan(data).any(axis=0)]\n",
    "\n",
    "    # Shuffle data\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # separate into observations and targets\n",
    "    X = data[:, 1:-1]\n",
    "    Y = data[:, -1]\n",
    "\n",
    "    # Optionally add non linear features\n",
    "    if non_linearities:\n",
    "        X_cl = X.copy()\n",
    "        n_var = X.shape[1]\n",
    "        for i in range(0, n_var):\n",
    "            for j in range(i, n_var):\n",
    "                f = np.expand_dims(X_cl[:, i]*X_cl[:, j], axis=1)\n",
    "                if f.max() != 0:\n",
    "                    X = np.concatenate((X, f), axis=1)\n",
    "\n",
    "    # normalize X\n",
    "    x_norm = np.max(X, axis=0)\n",
    "    X /= x_norm\n",
    "\n",
    "    # Split into train and validation\n",
    "    X_train = X[0:int(X.shape[0]*train_ratio), :]\n",
    "    Y_train = Y[0:int(Y.shape[0]*train_ratio)]\n",
    "    X_val = X[int(X.shape[0]*train_ratio)::, :]\n",
    "    Y_val = Y[int(Y.shape[0]*train_ratio)::]\n",
    "\n",
    "    return X_train, Y_train, X_val, Y_val\n",
    "\n",
    "# Load data\n",
    "X_train, Y_train, X_val, Y_val = get_data()\n",
    "n_feat = X_train.shape[1]\n",
    "\n",
    "print X_train.shape\n",
    "print '{} Training samples'.format(X_train.shape[0])\n",
    "print '{} Validation samples'.format(X_val.shape[0])\n",
    "print '{} observed variables'.format(n_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start!\n",
    "### Placeholders and variables\n",
    "To implement and run a linear model, we will use the [Keras backend module](http://keras.io/backend/), which provides an abstraction over Theano.\n",
    "\n",
    "First of all, we define the necessary variables and placeholders for our computational graph. Variables maintain state across executions of the computational graph, while placeholders are ways to feed the graph with external data.\n",
    "\n",
    "For the linear regression example, we need three variables: `w`, `b`, and the learning rate for SGD, `lr`. Two placeholders `x` and `target` are created to store $x_i$ and $y_i$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Placeholders and variables\n",
    "x = K.placeholder(shape=(None, n_feat))\n",
    "target = K.placeholder(shape=(1,))\n",
    "lr = K.variable(0.01)\n",
    "w = K.variable(np.random.rand(n_feat))\n",
    "b = K.variable(np.random.rand())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition\n",
    "Now we can define the $y = w^Tx + b$ relation as well as the MSE loss in the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model and loss\n",
    "y = K.dot(x, w) + b\n",
    "loss = K.mean(K.square(y-target))\n",
    "eval_loss = K.function(inputs=[x, target], outputs=[loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, given the gradient of MSE wrt to `w` and `b`, we can define how we update the parameters via SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradients\n",
    "grads = K.gradients(loss, [w, b])\n",
    "updates = [[w, w-lr*grads[0]], [b, b-lr*grads[1]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole model can be encapsulated in a `function`, which takes as input `x` and `target`, returns the current loss value and updates its parameter according to `updates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "train = K.function(inputs=[x, target], outputs=[loss], updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Training is now just a matter of calling the `function` we have just defined. Each time `train` is called, indeed, `w` and `b` will be updated using the SGD rule.\n",
    "\n",
    "We define a number of epochs at each of wich our dataset will be scanned. We can monitor both the loss on training and validation sets keeping a list, and print them and plot them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3996341248.000 \t Validation loss: 3552807936.000\n",
      "Training loss: 3689057024.000 \t Validation loss: 3352043776.000\n",
      "Training loss: 3501405696.000 \t Validation loss: 3167929856.000\n",
      "Training loss: 3328795136.000 \t Validation loss: 2995115008.000\n",
      "Training loss: 3169711104.000 \t Validation loss: 2835941120.000\n",
      "Training loss: 3023050752.000 \t Validation loss: 2689476352.000\n",
      "Training loss: 2887803392.000 \t Validation loss: 2554693120.000\n",
      "Training loss: 2763044352.000 \t Validation loss: 2430641408.000\n",
      "Training loss: 2647923200.000 \t Validation loss: 2316445696.000\n",
      "Training loss: 2541661696.000 \t Validation loss: 2211307520.000\n",
      "Training loss: 2443544832.000 \t Validation loss: 2114490496.000\n",
      "Training loss: 2352917248.000 \t Validation loss: 2025321344.000\n",
      "Training loss: 2269178112.000 \t Validation loss: 1943180800.000\n",
      "Training loss: 2191774976.000 \t Validation loss: 1867500800.000\n",
      "Training loss: 2120200960.000 \t Validation loss: 1797761280.000\n",
      "Training loss: 2053991552.000 \t Validation loss: 1733482496.000\n",
      "Training loss: 1992719872.000 \t Validation loss: 1674225536.000\n",
      "Training loss: 1935993600.000 \t Validation loss: 1619586816.000\n",
      "Training loss: 1883452288.000 \t Validation loss: 1569196032.000\n",
      "Training loss: 1834765952.000 \t Validation loss: 1522712320.000\n",
      "Training loss: 1789630208.000 \t Validation loss: 1479823488.000\n",
      "Training loss: 1747766272.000 \t Validation loss: 1440242304.000\n",
      "Training loss: 1708917376.000 \t Validation loss: 1403704576.000\n",
      "Training loss: 1672847744.000 \t Validation loss: 1369967744.000\n",
      "Training loss: 1639340928.000 \t Validation loss: 1338808960.000\n",
      "Training loss: 1608197120.000 \t Validation loss: 1310022912.000\n",
      "Training loss: 1579233152.000 \t Validation loss: 1283421952.000\n",
      "Training loss: 1552280576.000 \t Validation loss: 1258831616.000\n",
      "Training loss: 1527184256.000 \t Validation loss: 1236094080.000\n",
      "Training loss: 1503801600.000 \t Validation loss: 1215061504.000\n",
      "Training loss: 1482001536.000 \t Validation loss: 1195600000.000\n",
      "Training loss: 1461662720.000 \t Validation loss: 1177585024.000\n",
      "Training loss: 1442674176.000 \t Validation loss: 1160902912.000\n",
      "Training loss: 1424933376.000 \t Validation loss: 1145448320.000\n",
      "Training loss: 1408346368.000 \t Validation loss: 1131125120.000\n",
      "Training loss: 1392826112.000 \t Validation loss: 1117844224.000\n",
      "Training loss: 1378291840.000 \t Validation loss: 1105523584.000\n",
      "Training loss: 1364670976.000 \t Validation loss: 1094088064.000\n",
      "Training loss: 1351894528.000 \t Validation loss: 1083468288.000\n",
      "Training loss: 1339900800.000 \t Validation loss: 1073600640.000\n",
      "Training loss: 1328631296.000 \t Validation loss: 1064426048.000\n",
      "Training loss: 1318033152.000 \t Validation loss: 1055890240.000\n",
      "Training loss: 1308057088.000 \t Validation loss: 1047943616.000\n",
      "Training loss: 1298657536.000 \t Validation loss: 1040540416.000\n",
      "Training loss: 1289793280.000 \t Validation loss: 1033637696.000\n",
      "Training loss: 1281425280.000 \t Validation loss: 1027196928.000\n",
      "Training loss: 1273518208.000 \t Validation loss: 1021181952.000\n",
      "Training loss: 1266038528.000 \t Validation loss: 1015559680.000\n",
      "Training loss: 1258956672.000 \t Validation loss: 1010299840.000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFyCAYAAACgITN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSEiSpKYZJCRJUtMMEpIkqWn/H3YjYDH6ssSEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x457a438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs):\n",
    "    train_loss = train([X_train, Y_train])[0]\n",
    "    train_loss_history.append(train_loss)\n",
    "\n",
    "    val_loss = eval_loss([X_val, Y_val])[0]\n",
    "    val_loss_history.append(val_loss)\n",
    "\n",
    "    # Print and plot\n",
    "    if epoch % 20 == 0 and epoch != 0:\n",
    "        print \"Training loss: %.03f \\t Validation loss: %.03f\" % (train_loss, val_loss)\n",
    "\n",
    "        # Plot loss history\n",
    "        tr, = plt.plot(train_loss_history, c='r')\n",
    "        vl, = plt.plot(val_loss_history, c='b')\n",
    "        plt.legend([tr, vl], ['Train', 'Val'])\n",
    "        plt.xlim(0, nb_epochs)\n",
    "        plt.ylim(0, max(max(train_loss_history[3:]), max(val_loss_history[3:])))\n",
    "        plt.title('[Epoch: {}] Loss history'.format(epoch))\n",
    "            \n",
    "        plt.draw()\n",
    "        plt.pause(0.001)\n",
    "\n",
    "# Final plot (still)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
